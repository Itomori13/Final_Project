{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19713e81-d219-4db8-bf7a-bc3337bb6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Conv1D, Flatten\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180b06b-6f98-4ab3-96fa-1ae03f60f424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43f4285-dd3c-4850-8835-20fbdf440ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"SolarPrediction.csv\")\n",
    "\n",
    "# basic time analyse\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"Data\"], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "df[\"DatePart\"] = df[\"Datetime\"].dt.date\n",
    "\n",
    "print(\"Step 1 Complete - Basic Time Analysis\")\n",
    "print(\"Current column:\", df.columns.tolist())\n",
    "print(\"Data Sample:\")\n",
    "display(df[[\"Data\", \"Time\", \"Datetime\"]].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769438c8-9cf3-4e21-9aca-2f78465b791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"SolarPrediction.csv\")\n",
    "\n",
    "# basic time analyse\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"Data\"], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "df[\"DatePart\"] = df[\"Datetime\"].dt.date\n",
    "\n",
    "print(\"Step 1 Complete - Basic Time Analysis\")\n",
    "print(\"Current column:\", df.columns.tolist())\n",
    "print(\"Data Sample:\")\n",
    "display(df[[\"Data\", \"Time\", \"Datetime\"]].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f29f6-0a97-463c-91a9-9a353352a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# validate the time format\n",
    "def validate_time(time_str):\n",
    "    try:\n",
    "        pd.to_datetime(time_str, format=\"%H:%M:%S\")\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# delete irrelevant time\n",
    "valid_time_mask = df[\"Time\"].apply(validate_time)\n",
    "df = df[valid_time_mask].copy()\n",
    "\n",
    "# standardize time format\n",
    "df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%H:%M:%S\").dt.time\n",
    "\n",
    "# combine accurate timestamp\n",
    "df[\"Datetime\"] = pd.to_datetime(\n",
    "    df[\"DatePart\"].astype(str) + \" \" + df[\"Time\"].astype(str),\n",
    "    format=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "print(\"Step 2 Complete - Time Standardization\")\n",
    "print(\"Remaining Records:\", len(df))\n",
    "print(\"Time range:\", df[\"Datetime\"].min(), \"~\", df[\"Datetime\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac2746-5527-4e2e-b97f-958c13e79fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate sunrise time set\n",
    "df[\"SunRise\"] = pd.to_datetime(\n",
    "    df[\"DatePart\"].astype(str) + \" \" + df[\"TimeSunRise\"],\n",
    "    format=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# generate sunset time set\n",
    "df[\"SunSet\"] = pd.to_datetime(\n",
    "    df[\"DatePart\"].astype(str) + \" \" + df[\"TimeSunSet\"],\n",
    "    format=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# generate cross time problem\n",
    "mask = df[\"SunSet\"] < df[\"SunRise\"]\n",
    "df.loc[mask, \"SunSet\"] += pd.Timedelta(days=1)\n",
    "\n",
    "print(\"\\nStep 3 Complete - Sunrise and Sunset Time Processing\")\n",
    "print(\"Example of Sunrise and Sunset Time:\")\n",
    "display(df[[\"SunRise\", \"SunSet\"]].head(2))\n",
    "print(\"Is there an abnormal time\", df[\"SunRise\"].gt(df[\"SunSet\"]).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5ae15-1139-4fb8-a93d-4a34d972ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# time feature\n",
    "df['Hour'] = df['Datetime'].dt.hour\n",
    "df['DayOfYear'] = df['Datetime'].dt.dayofyear\n",
    "df['Season'] = df['Datetime'].dt.month % 12 // 3 + 1\n",
    "\n",
    "# Periodic coding\n",
    "df['Hour_sin'] = np.sin(2 * np.pi * df['Hour']/24)\n",
    "df['Hour_cos'] = np.cos(2 * np.pi * df['Hour']/24)\n",
    "\n",
    "# Astronomical characteristics\n",
    "df['DaylightDuration'] = (df['SunSet'] - df['SunRise']).dt.total_seconds() / 3600\n",
    "df['IsDaylight'] = ((df['Datetime'] >= df['SunRise']) & (df['Datetime'] <= df['SunSet'])).astype(int)\n",
    "df['SinceSunrise'] = (df['Datetime'] - df['SunRise']).dt.total_seconds() / 3600\n",
    "df['ToSunset'] = (df['SunSet'] - df['Datetime']).dt.total_seconds() / 3600\n",
    "\n",
    "# Wind direction coding\n",
    "df['WindDirection_sin'] = np.sin(np.radians(df['WindDirection(Degrees)']))\n",
    "df['WindDirection_cos'] = np.cos(np.radians(df['WindDirection(Degrees)']))\n",
    "\n",
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = ['Temperature', 'Pressure', 'Humidity', 'Speed']\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print(\"\\nStep4 Completion - Feature Engineering\")\n",
    "print(\"Add feature column:\", [c for c in df.columns if c not in [\"Data\", \"Time\", \"DatePart\"]])\n",
    "print(\"Standardized statistics:\")\n",
    "display(df[numeric_cols].describe().loc[[\"mean\", \"std\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc94f36-b674-4383-8056-aa217986d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "LOOKBACK = 24  # use 2-hour data before\n",
    "FORECAST = 12  # predict 1 hour later\n",
    "\n",
    "feature_columns = [\n",
    "    'Radiation',\n",
    "    'Hour_sin', 'Hour_cos',\n",
    "    'Temperature', 'Pressure', 'Humidity',\n",
    "    'WindDirection_sin', 'WindDirection_cos',\n",
    "    'Speed', 'IsDaylight',\n",
    "    'SinceSunrise', 'ToSunset'\n",
    "]\n",
    "\n",
    "def create_sequences(data, lookback, forecast):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - lookback - forecast + 1):\n",
    "        X.append(data.iloc[i:i+lookback][feature_columns].values)\n",
    "        y.append(data.iloc[i+lookback:i+lookback+forecast]['Radiation'].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(df, LOOKBACK, FORECAST)\n",
    "\n",
    "print(\"\\nStep5 Complete - Dataset Construction\")\n",
    "print(\"Input shape:\", X.shape)\n",
    "print(\"Output shape:\", y.shape)\n",
    "print(\"Verification of input dimension for the first sample:\", X[0].shape == (LOOKBACK, len(feature_columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea352ada-4368-4fc5-95ba-edd30aac3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(input_shape, forecast_steps):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # dual-path CNN\n",
    "    conv3 = Conv1D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv5 = Conv1D(64, 5, activation='relu', padding='same')(inputs)\n",
    "    merged_conv = concatenate([conv3, conv5])\n",
    "    \n",
    "    # double linked BiLSTM\n",
    "    bilstm = Bidirectional(LSTM(128, return_sequences=True))(merged_conv)\n",
    "    \n",
    "    # time attention\n",
    "    attention = Dense(1, activation='tanh')(bilstm)  # time attention weight\n",
    "    attention = Softmax(axis=1)(attention)\n",
    "    context = multiply([bilstm, attention])\n",
    "    \n",
    "    # output layer\n",
    "    flattened = Flatten()(context)\n",
    "    dense = Dense(256, activation='relu')(flattened)\n",
    "    outputs = Dense(forecast_steps)(dense)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae','mape'])\n",
    "    return model\n",
    "\n",
    "model = build_model((LOOKBACK, len(feature_columns)), FORECAST)\n",
    "print(\"\\nStep6 Completion - Model Construction\")\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2254c2-8597-40ed-aa7f-6cc2df97c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data split\n",
    "total_samples = len(X)\n",
    "train_size = int(0.7 * total_samples)\n",
    "val_size = int(0.85 * total_samples)\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:val_size], y[train_size:val_size]\n",
    "X_test, y_test = X[val_size:], y[val_size:]\n",
    "\n",
    "# train set\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b976d-6ddd-46a7-8388-dd6529442411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load best model\n",
    "from tensorflow.keras.models import load_model\n",
    "best_model = load_model(\"best_model.h5\")\n",
    "\n",
    "# directly use trained model if possible\n",
    "val_results = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "print(\"\\nTest results:\")\n",
    "print(f\"Loss (MSE): {val_results[0]:.4f}\")\n",
    "print(f\"MAE: {val_results[1]:.4f}\")\n",
    "print(f\"MAPE: {val_results[2]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd75832-813d-4436-9483-9e3d26314a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['mae'], label='train')\n",
    "plt.plot(history.history['val_mae'], label='val')\n",
    "plt.title('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['mape'], label='train')\n",
    "plt.plot(history.history['val_mape'], label='val')\n",
    "plt.title('MAPE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0acfaa-e567-4ffa-8175-723154724595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention weights submodel\n",
    "attention_model = Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"softmax\").output  # match layer with model\n",
    ")\n",
    "\n",
    "# Get attention weights for validation samples\n",
    "attention_weights = attention_model.predict(X_val[:100])  # shape: (100, 24, 1)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Single sample\n",
    "plt.subplot(2, 1, 1)\n",
    "sample_idx = 0\n",
    "plt.plot(attention_weights[sample_idx].squeeze(), 'o-', color='#FF6B6B', linewidth=2)\n",
    "plt.title(f\"Sample {sample_idx} Temporal Attention (LOOKBACK=24)\")\n",
    "plt.xlabel(\"Historical Time Steps (5-min interval)\")\n",
    "plt.ylabel(\"Attention Weight\")\n",
    "plt.xticks(range(0, 24, 3), [f\"t-{24-i}\" for i in range(0, 24, 3)])\n",
    "\n",
    "# Average across samples\n",
    "plt.subplot(2, 1, 2)\n",
    "mean_weights = np.mean(attention_weights, axis=0).squeeze()\n",
    "plt.plot(mean_weights, 's-', color='#4ECDC4', linewidth=2)\n",
    "plt.title(\"Average Attention Weights Across Samples\")\n",
    "plt.xlabel(\"Historical Time Steps (5-min interval)\")\n",
    "plt.ylabel(\"Mean Weight\")\n",
    "plt.xticks(range(0, 24, 3), [f\"t-{24-i}\" for i in range(0, 24, 3)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a759218-9b73-4595-ac13-ab80df0c31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CNN outputs\n",
    "conv3_model = Model(inputs=model.input, outputs=model.get_layer(\"conv1d\").output)\n",
    "conv5_model = Model(inputs=model.input, outputs=model.get_layer(\"conv1d_1\").output)\n",
    "\n",
    "# Calculate activation magnitudes\n",
    "conv3_act = np.mean(np.abs(conv3_model.predict(X_val[:100])))\n",
    "conv5_act = np.mean(np.abs(conv5_model.predict(X_val[:100])))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(['3x3 Conv', '5x5 Conv'], [conv3_act, conv5_act], color=['#FF9F40', '#55CBCD'])\n",
    "plt.ylabel(\"Mean Activation Magnitude\")\n",
    "plt.title(\"Dual-path CNN Contribution Comparison\")\n",
    "plt.grid(axis='y', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48026f4e-3855-4294-930b-6ecab962d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract BiLSTM outputs\n",
    "bilstm_model = Model(inputs=model.input, outputs=model.get_layer(\"bidirectional\").output)\n",
    "bilstm_output = bilstm_model.predict(X_val[:10])  # (10, 24, 256)\n",
    "\n",
    "# Activation heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(bilstm_output[0].T, cmap='viridis', aspect='auto')\n",
    "plt.colorbar(label=\"Activation Strength\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Neuron Index\")\n",
    "plt.title(\"BiLSTM Layer Activation Pattern (Sample 0)\")\n",
    "plt.xticks(range(0, 24, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7841fef-2ba7-42bd-8217-64a0b2d75c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain attention weight\n",
    "attention_model = Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"softmax\").output\n",
    ")\n",
    "att_weights = attention_model.predict(X_val[:100])  # (100, 24, 1)\n",
    "\n",
    "# Visualize the average attention distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(np.mean(att_weights, axis=0).squeeze(), 'o-', color='#E64A45')\n",
    "plt.title(\"Average Attention Weights Across Time Steps\")\n",
    "plt.xlabel(\"Time Step (5-min interval)\")\n",
    "plt.ylabel(\"Attention Weight\")\n",
    "plt.xticks(range(0, 24, 3), [f\"t-{24-i}\" for i in range(0, 24, 3)])\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36133ec-fcee-487a-8310-c7d292c0cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict model construction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "for i in np.random.choice(range(len(y_test)), 2):\n",
    "    plt.subplot(3, 1, (i%3)+1)\n",
    "    plt.plot(y_test[i], label='True')\n",
    "    plt.plot(y_pred[i], label='Predicted')\n",
    "    plt.title(f'Sample {i} Forecast Comparison')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Radiation')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8870eda4-6e68-4ee0-8b71-421d78f9c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Create  joint distribution map\n",
    "g = sns.jointplot(x=y_test.flatten(), \n",
    "                y=y_pred.flatten(), \n",
    "                kind='hex',\n",
    "                height=8,\n",
    "                ratio=5,\n",
    "                space=0.2,\n",
    "                joint_kws={'gridsize': 50},\n",
    "                marginal_kws={'bins': 30, 'fill': True})\n",
    "\n",
    "\n",
    "g.set_axis_labels('True Values', 'Predictions', fontsize=12)\n",
    "g.fig.suptitle(f'Global Prediction Performance (RMSE={test_rmse:.2f}, R²={test_r2:.2f})', \n",
    "             y=1.02,\n",
    "             fontsize=14)\n",
    "\n",
    "# Add the ideal diagonal\n",
    "x0, x1 = g.ax_joint.get_xlim()\n",
    "y0, y1 = g.ax_joint.get_ylim()\n",
    "lims = [max(x0, y0), min(x1, y1)]\n",
    "g.ax_joint.plot(lims, lims, 'r--', alpha=0.7, linewidth=1.5)\n",
    "\n",
    "\n",
    "plt.colorbar(g.ax_joint.collections[0], ax=g.ax_joint, label='Data density')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2158700-fdd9-4c29-9ffa-704bc110f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = y_test - y_pred\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(errors.flatten(), bins=50, kde=True)\n",
    "plt.title('Prediction Error Distribution')\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36a6e1-a40a-44d4-8acf-4cae8b75bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step_rmse = np.sqrt(np.mean((y_test - y_pred)**2, axis=0))\n",
    "step_mae = np.mean(np.abs(y_test - y_pred), axis=0)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(step_rmse, 's-', label='RMSE per Step')\n",
    "plt.plot(step_mae, 'o-', label='MAE per Step')\n",
    "plt.title('Error Analysis by Forecast Step')\n",
    "plt.xlabel('Forecast Time Step')\n",
    "plt.ylabel('Error Value')\n",
    "plt.xticks(range(FORECAST), [f'T+{i+1}' for i in range(FORECAST)])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06475ab-6c19-4747-a890-22aec1023c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test.flatten(), y_pred.flatten(), \n",
    "            alpha=0.3, \n",
    "            c='blue',\n",
    "            edgecolors='w')\n",
    "plt.plot([y_test.min(), y_test.max()], \n",
    "         [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2)\n",
    "plt.xlabel('True Values', fontsize=12)\n",
    "plt.ylabel('Predictions', fontsize=12)\n",
    "plt.title(f'True vs Predicted Values (R²={test_r2:.2f})', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.colorbar(label='Data density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a80e67-e534-4e62-a1b7-f236af16427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "quantiles = np.percentile(y_test.flatten(), np.linspace(0, 100, 20))\n",
    "pred_quantiles = np.percentile(y_pred.flatten(), np.linspace(0, 100, 20))\n",
    "\n",
    "plt.plot(quantiles, pred_quantiles, 'bo-')\n",
    "plt.plot([quantiles.min(), quantiles.max()], \n",
    "         [quantiles.min(), quantiles.max()], \n",
    "         'r--', lw=2)\n",
    "plt.xlabel('True Value Quantiles', fontsize=12)\n",
    "plt.ylabel('Predicted Value Quantiles', fontsize=12)\n",
    "plt.title('Quantile-Quantile Comparison', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b79d1-e65f-4d85-967d-48153284ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = y_pred - y_test\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=pd.DataFrame(errors, \n",
    "                            columns=[f'T+{i+1}' for i in range(FORECAST)]),\n",
    "           orient='v',\n",
    "           palette='Set2')\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.title('Prediction Error Distribution per Time Step')\n",
    "plt.ylabel('Prediction Error')\n",
    "plt.xlabel('Forecast Step')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf01d8-8f33-401c-bb33-1ea446d725d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(y_test.flatten(), \n",
    "           label='True Values', \n",
    "           color='blue',\n",
    "           linewidth=2)\n",
    "sns.kdeplot(y_pred.flatten(), \n",
    "           label='Predictions', \n",
    "           color='red',\n",
    "           linestyle='--',\n",
    "           linewidth=2)\n",
    "plt.xlabel('Radiation Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Probability Distribution Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb7169-c954-4eb6-8ca7-f136bdf89bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Use hexbin to handle high-density data\n",
    "hb = plt.hexbin(y_test.flatten(), y_pred.flatten(), \n",
    "                gridsize=100, \n",
    "                cmap='viridis',\n",
    "                mincnt=1,\n",
    "                bins='log')\n",
    "\n",
    "plt.plot([y_test.min(), y_test.max()], \n",
    "         [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2)\n",
    "plt.colorbar(hb, label='log10(N)')\n",
    "plt.xlabel('True Values', fontsize=12)\n",
    "plt.ylabel('Predictions', fontsize=12)\n",
    "plt.title(f'Complete Value Comparison (N={len(y_test.flatten()):,} points)', fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374a511-9966-4f65-89b3-183a21da2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(18, 12), sharey=True)\n",
    "axes = axes.flatten()\n",
    "for step in range(y_test.shape[1]):\n",
    "    try:\n",
    "        ax = axes[step]\n",
    "        ax.scatter(y_test[:, step], y_pred[:, step], \n",
    "                   alpha=0.3, \n",
    "                   c='teal',\n",
    "                   edgecolors='none')\n",
    "        ax.plot([y_test.min(), y_test.max()], \n",
    "                [y_test.min(), y_test.max()], \n",
    "                'r--', lw=1.5)\n",
    "        ax.set_title(f'Step T+{step+1}')\n",
    "        ax.set_xlabel('True')\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "        # add index\n",
    "        rmse = np.sqrt(mean_squared_error(y_test[:, step], y_pred[:, step]))\n",
    "        ax.text(0.05, 0.85, f'RMSE: {rmse:.2f}', \n",
    "                transform=ax.transAxes,\n",
    "                backgroundcolor='white')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.suptitle('Per-Step Prediction Performance', y=1.02, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764948f4-2efc-49fc-99a2-13b3404786fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# use the sample\n",
    "sample_idx = np.random.choice(len(y_test), 200, replace=False)\n",
    "\n",
    "# generate curve\n",
    "for idx in sample_idx:\n",
    "    plt.plot(y_test[idx], color='blue', alpha=0.03, lw=1)\n",
    "    plt.plot(y_pred[idx], color='red', alpha=0.03, lw=1)\n",
    "\n",
    "# generate average curve\n",
    "plt.plot(np.mean(y_test, axis=0), 'b-', lw=3, label='True Mean')\n",
    "plt.plot(np.mean(y_pred, axis=0), 'r--', lw=3, label='Predicted Mean')\n",
    "\n",
    "plt.xlabel('Forecast Steps', fontsize=12)\n",
    "plt.ylabel('Radiation', fontsize=12)\n",
    "plt.title('Complete Temporal Comparison', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d405c80-ac9f-4b1d-91e7-06f69e5d5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix generation\n",
    "error_matrix = np.abs(y_pred - y_test)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(error_matrix.T,\n",
    "            cmap='YlOrRd',\n",
    "            cbar_kws={'label': 'Absolute Error'},\n",
    "            vmin=0,\n",
    "            vmax=np.percentile(error_matrix, 95))\n",
    "\n",
    "plt.xlabel('Sample Index', fontsize=12)\n",
    "plt.ylabel('Forecast Steps', fontsize=12)\n",
    "plt.title('Spatiotemporal Error Distribution', fontsize=14)\n",
    "plt.xticks([])\n",
    "plt.yticks(ticks=range(0, y_test.shape[1], 2), \n",
    "           labels=[f'T+{i+1}' for i in range(0, y_test.shape[1], 2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33355706-6126-4014-a34b-2d48c0addd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y_pred - y_test\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.boxplot(data=pd.DataFrame(error, \n",
    "                            columns=[f'T+{i+1}' for i in range(error.shape[1])]),\n",
    "           orient='v',\n",
    "           palette='coolwarm',\n",
    "           showfliers=False,\n",
    "           notch=True)\n",
    "\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=1.5)\n",
    "plt.title('Error Distribution Across Forecast Steps')\n",
    "plt.ylabel('Prediction Error')\n",
    "plt.xlabel('Forecast Step')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26637d0-ef06-45c8-827b-d44003f67299",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# calculate CDF\n",
    "def ecdf(data):\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, len(x)+1)/len(x)\n",
    "    return x, y\n",
    "\n",
    "x_true, y_true = ecdf(y_test.flatten())\n",
    "x_pred, y_pred_cdf = ecdf(y_pred.flatten())\n",
    "\n",
    "plt.plot(x_true, y_true, label='True CDF', lw=2)\n",
    "plt.plot(x_pred, y_pred_cdf, label='Predicted CDF', lw=2, linestyle='--')\n",
    "plt.fill_betweenx(y_true, x_true, x_pred, \n",
    "                 where=(x_pred >= x_true), \n",
    "                 color='green', alpha=0.1,\n",
    "                 label='Over-prediction Area')\n",
    "plt.fill_betweenx(y_true, x_true, x_pred,\n",
    "                 where=(x_pred < x_true),\n",
    "                 color='red', alpha=0.1,\n",
    "                 label='Under-prediction Area')\n",
    "\n",
    "plt.title('Empirical Cumulative Distribution Function Comparison')\n",
    "plt.xlabel('Radiation Value')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3d9d2-7a3b-48fb-9c55-28dcda9b33d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_time_step_distribution(data, title):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Use kernel density estimation\n",
    "    sns.violinplot(data=pd.DataFrame(data, \n",
    "                                   columns=[f'T+{i+1}' for i in range(data.shape[1])]),\n",
    "                  palette=\"Spectral\",\n",
    "                  inner=\"quartile\",\n",
    "                  cut=0)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Forecast Step')\n",
    "    plt.ylabel('Radiation Value')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "plot_time_step_distribution(y_test, 'True Values Distribution Across Steps')\n",
    "plot_time_step_distribution(y_pred, 'Predicted Values Distribution Across Steps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cffcb-77f9-4ea6-ace7-26d8bf2be664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# create data frame\n",
    "df = pd.DataFrame({\n",
    "    'True': y_test.flatten(),\n",
    "    'Predicted': y_pred.flatten(),\n",
    "    'Residual': (y_pred - y_test).flatten()\n",
    "})\n",
    "\n",
    "# Calculate statistical indicators\n",
    "pearson_r, pearson_p = stats.pearsonr(df['True'], df['Predicted'])\n",
    "spearman_r = stats.spearmanr(df['True'], df['Predicted']).correlation\n",
    "\n",
    "# Draw the enhanced scatter plot\n",
    "g = sns.jointplot(data=df, x='True', y='Predicted',\n",
    "                 kind='reg', \n",
    "                 scatter_kws={'alpha':0.3, 's':5},\n",
    "                 line_kws={'color':'red', 'lw':2},\n",
    "                 ratio=4,\n",
    "                 marginal_ticks=True)\n",
    "\n",
    "\n",
    "text = (f\"Pearson r = {pearson_r:.3f} (p={pearson_p:.2e})\\n\"\n",
    "        f\"Spearman ρ = {spearman_r:.3f}\\n\"\n",
    "        f\"N = {len(df):,}\")\n",
    "g.ax_joint.text(0.05, 0.95, text, \n",
    "               transform=g.ax_joint.transAxes,\n",
    "               ha='left', va='top',\n",
    "               bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "# Add quantile reference lines\n",
    "for q in [0.1, 0.5, 0.9]:\n",
    "    g.ax_joint.axhline(np.quantile(df['Predicted'], q), \n",
    "                      color='grey', ls=':', alpha=0.5)\n",
    "    g.ax_joint.axvline(np.quantile(df['True'], q), \n",
    "                      color='grey', ls=':', alpha=0.5)\n",
    "\n",
    "plt.suptitle('Enhanced Correlation Analysis', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6826b0-e618-47a3-a472-cbf7b7d76994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation coefficients of each time step\n",
    "corr_matrix = np.array([[\n",
    "    np.corrcoef(y_test[:,i], y_pred[:,j])[0,1] \n",
    "    for j in range(y_pred.shape[1])]\n",
    "    for i in range(y_test.shape[1])\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix,\n",
    "           annot=True,\n",
    "           fmt=\".2f\",\n",
    "           cmap='coolwarm',\n",
    "           vmin=-1, vmax=1,\n",
    "           mask=np.triu(np.ones_like(corr_matrix)),\n",
    "           linewidths=0.5,\n",
    "           cbar_kws={'label': 'Pearson Correlation'})\n",
    "\n",
    "plt.title('Spatiotemporal Correlation Matrix')\n",
    "plt.xlabel('Prediction Steps')\n",
    "plt.ylabel('True Value Steps')\n",
    "plt.xticks(ticks=np.arange(0.5, y_pred.shape[1]+0.5), \n",
    "          labels=[f'P_T+{i+1}' for i in range(y_pred.shape[1])])\n",
    "plt.yticks(ticks=np.arange(0.5, y_test.shape[1]+0.5), \n",
    "          labels=[f'T_T+{i+1}' for i in range(y_test.shape[1])])\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a2fc98-9d15-436b-8c2e-40dd754b867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.linspace(0, 1, 100)\n",
    "q_true = np.quantile(y_test, quantiles)\n",
    "q_pred = np.quantile(y_pred, quantiles)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.regplot(x=q_true, y=q_pred, \n",
    "           scatter_kws={'alpha':0.6},\n",
    "           line_kws={'color':'red', 'lw':2})\n",
    "\n",
    "# Draw the confidence interval\n",
    "sns.regplot(x=q_true, y=q_pred, \n",
    "           ci=99, \n",
    "           scatter=False, \n",
    "           line_kws={'color':'red', 'alpha':0.2})\n",
    "\n",
    "plt.plot([q_true.min(), q_true.max()], \n",
    "        [q_true.min(), q_true.max()], \n",
    "        'k--', alpha=0.5)\n",
    "plt.title('Quantile Correlation Plot')\n",
    "plt.xlabel('True Values Quantiles')\n",
    "plt.ylabel('Predicted Values Quantiles')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.text(0.05, 0.9, \n",
    "        f'Kendall τ = {stats.kendalltau(q_true, q_pred)[0]:.3f}',\n",
    "        transform=plt.gca().transAxes,\n",
    "        bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac55cd6-7a45-40fd-81ae-602876efdecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the feature name (combining time steps and features)\n",
    "feature_names = [\n",
    "    f\"t-{LOOKBACK-i-1}_{feat}\"\n",
    "    for i in range(LOOKBACK)\n",
    "    for feat in feature_columns\n",
    "]\n",
    "\n",
    "# Lime creation\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_train.reshape(-1, LOOKBACK*len(feature_columns))[:1000],  # use trained data\n",
    "    feature_names=feature_names,\n",
    "    mode=\"regression\",\n",
    "    discretize_continuous=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# generate predict function\n",
    "def predict_fn(x):\n",
    "    # Convert the 2D input into a 3D time series format\n",
    "    x_reshaped = x.reshape(-1, LOOKBACK, len(feature_columns))\n",
    "    return model.predict(x_reshaped)\n",
    "\n",
    "# explanation\n",
    "sample_idx = 0\n",
    "sample_to_explain = X_test[sample_idx].flatten()\n",
    "\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    data_row=sample_to_explain,\n",
    "    predict_fn=predict_fn,\n",
    "    num_features=20,\n",
    "    num_samples=5000\n",
    ")\n",
    "\n",
    "# visible lime explanation\n",
    "plt.figure(figsize=(10, 6))\n",
    "explanation.as_pyplot_figure()\n",
    "plt.title(f\"LIME Explanation for Sample {sample_idx}\")\n",
    "plt.show()\n",
    "\n",
    "# Output the temporal feature importance map\n",
    "exp_list = explanation.as_list()\n",
    "print(\"\\nTop important characteristics ：\")\n",
    "for feature, importance in exp_list:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
